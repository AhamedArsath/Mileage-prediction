
### *Import Library:*
python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler


---

### *Import Data:*
python
# Example: Load a dataset from a CSV file
house_data = pd.read_csv('house_data.csv')


---

### *Describe Data:*
python
# Overview of the dataset
print(house_data.info())
print(house_data.describe())
print(house_data.head())

# Check for missing values
print(house_data.isnull().sum())

*Explanation*: The dataset may include columns like house size (sqft), number of bedrooms, bathrooms, location, year built, etc. Understanding missing data and the structure is crucial.

---

### *Data Visualization:*
python
# Visualizing the correlation between different features
plt.figure(figsize=(10, 8))
sns.heatmap(house_data.corr(), annot=True, cmap='coolwarm')
plt.title('Feature Correlation Heatmap')
plt.show()

# Distribution of house prices
sns.histplot(house_data['price'], bins=50, kde=True)
plt.title('Distribution of House Prices')
plt.show()

# Visualizing relationship between house size and price
sns.scatterplot(x='sqft_living', y='price', data=house_data)
plt.title('House Size vs Price')
plt.show()


---

### *Data Preprocessing:*
python
# Handling missing values
house_data.fillna(method='ffill', inplace=True)

# Dropping irrelevant columns
house_data = house_data.drop(['id', 'date', 'zipcode'], axis=1)

# Converting categorical columns (if any) using one-hot encoding
house_data = pd.get_dummies(house_data, columns=['waterfront', 'condition', 'grade'], drop_first=True)

# Feature scaling (especially for numerical features like sqft, lot size)
scaler = StandardScaler()
scaled_columns = ['sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement']
house_data[scaled_columns] = scaler.fit_transform(house_data[scaled_columns])


---

### *Define Target Variable (y) and Feature Variables (X):*
python
# Defining features and target variable
X = house_data.drop('price', axis=1)
y = house_data['price']


---

### *Train Test Split:*
python
# Splitting the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)


---

### *Modeling:*
1. *Linear Regression:*
python
# Linear Regression Model
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)

# Predictions
y_pred_lr = lr_model.predict(X_test)


2. *Random Forest Regressor:*
python
# Random Forest Regressor Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Predictions
y_pred_rf = rf_model.predict(X_test)


---

### *Model Evaluation:*
1. *Linear Regression Evaluation:*
python
# Mean Squared Error & R-squared for Linear Regression
mse_lr = mean_squared_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print(f"Linear Regression MSE: {mse_lr}")
print(f"Linear Regression R2 Score: {r2_lr}")


2. *Random Forest Evaluation:*
python
# Mean Squared Error & R-squared for Random Forest
mse_rf = mean_squared_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

print(f"Random Forest MSE: {mse_rf}")
print(f"Random Forest R2 Score: {r2_rf}")


---

### *Prediction:*
python
# Predict the price for a new house with certain features
new_house = np.array([[4, 3, 2000, 5000, 1000, 1000, 2, 1, 7, 2020]])  # Example features: Bedrooms, Bathrooms, Sqft, etc.
predicted_price = rf_model.predict(new_house)
print(f"Predicted Price for the new house: ${predicted_price[0]}")

